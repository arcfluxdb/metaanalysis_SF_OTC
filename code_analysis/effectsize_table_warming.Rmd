---
title: "table_with_effectsizes"
author: "Sarah"
date: "2024-01-26"
output: html_document
---

## Hallo Jan Hallo Sarah
# set up and load in data
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/1_projects and publications/4_flux data/1_winter flux data/1_R/winter flux/metaanalysis_SF_OTC")
source("code_data/data_cleaning.R") # get up-to date dataset

# file.exists("data_cleaning.R")
# 
# all_data <- readRDS("database/database.rds")$fluxdata
# 
# 
# all_data <- all_data %>%
#    mutate(treatment = ifelse(treatment == "sf", "SNOWFENCE",
#                              ifelse(treatment == "ctl", "CTL",treatment)))
# 
# site_data <- readRDS("database/database.rds")$sitedata
# 
# #filter treatments we are interested in
# working_data <- all_data %>% 
#   filter(!is.na(reco)) %>% 
#   filter(treatment %in% c("CTL", "OTC","SNOWFENCE","OTCxSNOWFENCE")) %>% 
#   filter(site_id_automatic != "AUS_1")  
# 
# working_data <- working_data %>%
#     mutate(flux_date = parse_date_time(flux_date, orders = c("ymd", "mdy", "dmy")))
# 
# ccolnames(working_data) <- gsub("_automatic","", colnames(working_data))
# 
# site_data$year <- as.numeric(site_data$year)
# site_data <- site_data[!duplicated(site_data[,c(1,2)]),]
# 
# working_data <- working_data %>%
#   dplyr::left_join(site_data, by = c("site_id" = "site_id", "flux_year" = "year"))
# 
# outlierremoval <- working_data %>% 
#   group_by(site_id,flux_year) %>% 
#   dplyr::summarise(recosd = sd(reco, na.rm=T),
#                    recomean = mean(reco, na.rm=T))
# outlierremoval$upper <- outlierremoval$recomean + 3 * (outlierremoval$recosd)  
# outlierremoval$lower <- outlierremoval$recomean - 3 * (outlierremoval$recosd)  
# 
# working_data <- working_data %>% 
#   dplyr::left_join(outlierremoval[,c(1,2,5,6)])
# 
# working_data$outlier <- with(working_data, reco < lower | reco > upper)
# 
# working_data <- working_data[!working_data$outlier,]
# 
# working_data <- working_data %>% 
#   mutate(air_temp = ifelse(is.na(air_temp),NA, as.numeric(air_temp)))
# 
# as.numeric(working_data$air_temp)
# 
# working_data$air_temp[grepl("NA", working_data$air_temp)] <- NA
# 
# working_data$air_temp[!is.na(working_data$air_temp)] <- as.numeric(working_data$air_temp[!is.na(working_data$air_temp)])

# #working_data$monthseason <- ifelse(working_data$month <= 3,"NGS",
#                                    ifelse(working_data$month <= 5, "Shoulder",
#                                           ifelse(working_data$month <= 9, "GS",
#                                                  ifelse(working_data$month <= 11, "Shoulder", "NGS"))))
```

```{r calculate N, mean and sd}
GRE_1->subset(working_data, site_id=="GRE_1",)


check<- working_data %>% 
  filter(!is.na(reco)) %>% 
  filter(treatment %in% c("CTL", "OTC","SNOWFENCE","OTCxSNOWFENCE"))
check$site_id<-as.factor(check$site_id)
c<-levels(check$site_id)

# Define variables of interest
variables_of_interest <- c("reco")

# Summarize multiple variables
summary_stats <- working_data %>%
  group_by(site_id, flux_year, treatment,flux_id, month) %>%
  dplyr::summarize_at(vars(variables_of_interest),
                      list(mean = ~mean(., na.rm = TRUE),
                           sd = ~sd(., na.rm = TRUE),
                           n = ~n()))

# Separate data for treatments OTC and SF using filter
ctl <- summary_stats %>% dplyr::filter(treatment == "CTL")

treat <- summary_stats %>% dplyr::filter(treatment %in% c("OTC","SNOWFENCE","OTCxSNOWFENCE"))
effect_df <- full_join(ctl, treat, by = c("site_id", "flux_year","flux_id", "month"),
                       suffix = c("_ctl", "_tr"))


# # split all
# otc <- summary_stats %>% dplyr::filter(treatment == "OTC")
# snow_fence <- summary_stats %>% dplyr::filter(treatment == "SNOWFENCE")
# snow_fence_otc <- summary_stats %>% dplyr::filter(treatment == "OTCxSNOWFENCE")
# 
# effect_df1 <- full_join(otc, snow_fence, by = c("site_id", "flux_year","flux_id", "month"),
#                        suffix = c("_otc", "_sf"))
# 
# effect_df2 <- full_join(ctl, snow_fence_otc, by = c("site_id", "flux_year","flux_id", "month"),
#                        suffix = c("_ctl", "_otc_sf"))
# 
# effect_df <- full_join(effect_df1, effect_df2, by = c("site_id", "flux_year","flux_id", "month"),
#                        suffix = c("", ""))
```

```{r effect size calculation}
library(metafor)

effect_sizes <-
  escalc( # This is the function in metafor that allows us to calculate an effect size for each row in a database
    "SMD",
    # Specify the effect size we want to calculate. In this case SMD for Standardized mean difference
    m1i = mean_tr,
    # mean richness at invaded sites
    n1i = n_tr,
    # invaded site sample size
    sd1i = sd_tr,
    # invaded site SD
    m2i = mean_ctl,
    # mean richness at control sites
    n2i = n_ctl,
    # control site sample size
    sd2i = sd_ctl,
    # control site SD
    data = effect_df # This is where the escalc function can find all the data for our meta-analysis
  )

```

```{r seperate for otc and sf}
# otc_effect_sizes <-
#   escalc( # This is the function in metafor that allows us to calculate an effect size for each row in a database
#     "SMD",
#     # Specify the effect size we want to calculate. In this case SMD for Standardized mean difference
#     m1i = mean_otc,
#     # mean richness at invaded sites
#     n1i = n_otc,
#     # invaded site sample size
#     sd1i = sd_otc,
#     # invaded site SD
#     m2i = mean_ctl,
#     # mean richness at control sites
#     n2i = n_ctl,
#     # control site sample size
#     sd2i = sd_ctl,
#     # control site SD
#     data = effect_df # This is where the escalc function can find all the data for our meta-analysis
#   )
# 
# colnames(otc_effect_sizes) <- gsub("yi", "yi_otc",colnames(otc_effect_sizes))
# colnames(otc_effect_sizes) <- gsub("vi", "vi_otc",colnames(otc_effect_sizes))
# 
# sf_effect_sizes <-
#   escalc( # This is the function in metafor that allows us to calculate an effect size for each row in a database
#     "SMD",
#     # Specify the effect size we want to calculate. In this case SMD for Standardized mean difference
#     m1i = mean_sf,
#     # mean richness at invaded sites
#     n1i = n_sf,
#     # invaded site sample size
#     sd1i = sd_sf,
#     # invaded site SD
#     m2i = mean_ctl,
#     # mean richness at control sites
#     n2i = n_ctl,
#     # control site sample size
#     sd2i = sd_ctl,
#     # control site SD
#     data = effect_df # This is where the escalc function can find all the data for our meta-analysis
#   )
# 
# colnames(sf_effect_sizes) <- gsub("yi", "yi_sf",colnames(sf_effect_sizes))
# colnames(sf_effect_sizes) <- gsub("vi", "vi_sf",colnames(sf_effect_sizes))
# 
# otc_sf_effect_sizes <-
#   escalc( # This is the function in metafor that allows us to calculate an effect size for each row in a database
#     "SMD",
#     # Specify the effect size we want to calculate. In this case SMD for Standardized mean difference
#     m1i = mean_otc_sf,
#     # mean richness at invaded sites
#     n1i = n_otc_sf,
#     # invaded site sample size
#     sd1i = sd_otc_sf,
#     # invaded site SD
#     m2i = mean_ctl,
#     # mean richness at control sites
#     n2i = n_ctl,
#     # control site sample size
#     sd2i = sd_ctl,
#     # control site SD
#     data = effect_df # This is where the escalc function can find all the data for our meta-analysis
#   )
# 
# colnames(otc_sf_effect_sizes) <- gsub("yi", "yi_otc_sf",colnames(otc_sf_effect_sizes))
# colnames(otc_sf_effect_sizes) <- gsub("vi", "vi_otc_sf",colnames(otc_sf_effect_sizes))
```

```{r overview datapoints}
library(tidyverse)

result_table <- working_data %>%
  group_by(site_id, treatment) %>%
  summarise(across(everything(), ~sum(!is.na(.))))

print(result_table)
#write.csv(result_table, "data_overview.csv")
```

# run multivariate effects model

```{r treatment comparison}
#comparison treatments
model_all<- rma.mv(yi, vi, 
                   mods = ~as.factor(treatment_tr),
                random=list(~ 1 | site_id, 
                            ~ flux_year | site_id), 
                struct="CAR", 
                data=effect_sizes)
summary(SF_total)
forest(SF_total)
predict(SF_total)


library(emmeans)
#posthoc
posthoc <- qdrg(object = model_all, data = effect_sizes)
cld(posthoc)
ph <- emmeans(posthoc, ~treatment_tr)
pairs(ph)


#plot
library(orchaRd)
model_results <- orchaRd::mod_results(model_all, mod = "treatment_tr", group="site_id", data=effect_sizes)

orchard_plot(model_results, mod = "treatment_tr", transfm = "none",
             xlab = "Ecosystem Respiration SMD",
             trunk.size = 0.8)+
  scale_fill_manual(
    values = c("darkgrey","steelblue","#FFBD17FF")) +
  scale_color_manual(
    values = c("darkgrey","steelblue","#FFBD17FF")) +
  theme_void()+
  theme(text = element_text(family = "sans"),
        axis.text = element_text(size = 13),
        axis.title = element_text(size = 13))+
  theme(legend.position= c(0.5, 0.05),
        legend.justification = c(0,1),
        legend.key.size = unit(1, "mm")) +
  theme(legend.direction="horizontal",
        legend.position = "bottom",
        legend.title = element_text(size =10),
        legend.text = element_text(size = 10))

```

#SF
```{r SF}
#SF
SF_total <- rma.mv(yi, vi, 
                   #mods = ~site_id,
                random=list(~ 1 | site_id, 
                            ~ flux_year | site_id), 
                struct="CAR", 
                data=subset(effect_sizes, treatment_tr=="SNOWFENCE"))
summary(SF_total)
forest(SF_total)
predict(SF_total)

sf_effect_sizes$site_id <- as.factor(sf_effect_sizes$site_id)
SF_na <- sf_effect_sizes[complete.cases(sf_effect_sizes$yi_sf), ]
#orchard plot
model_results_SF <- orchaRd::mod_results(SF_total, mod = "1", group="site_id", data=effect_sizes)

orchard_plot(model_results_SF, mod = "1", transfm = "none",
             xlab = "Ecosystem Respiration SMD",
             trunk.size = 0.8)+
  scale_fill_manual(
    values = c("#FFBD17FF")) +
  scale_color_manual(
    values = c("#FFBD17FF")) +
  theme_void()+
  theme(text = element_text(family = "sans"),
        axis.text = element_text(size = 13),
        axis.title = element_text(size = 13))+
  theme(legend.position= c(0.5, 0.05),
        legend.justification = c(0,1),
        legend.key.size = unit(1, "mm")) +
  theme(legend.direction="horizontal",
        legend.position = "bottom",
        legend.title = element_text(size =10),
        legend.text = element_text(size = 10))

```

#OTC
```{r  OTC}
#total
OTC_total <- rma.mv(yi, vi, 
                    #mods= ~as.factor(site_id),
                    random=list(~ 1 | site_id,
                                ~ flux_year | site_id), 
                    struct="CAR", 
                    data=subset(effect_sizes, treatment_tr=="OTC"),
                    control = list(iter.max = 100000))  # Increase iterations

summary(OTC_total)
forest(OTC_total)
predict(OTC_total)

#OTC_na <- otc_effect_sizes[complete.cases(otc_effect_sizes$yi_otc), ]
model_results_OTC <- orchaRd::mod_results(OTC_total, mod = "1", group="site_id", data=effect_sizes)

orchard_plot(model_results_OTC, mod = "1", transfm = "none",
             xlab = "Ecosystem Respiration SMD",
             trunk.size = 0.8)+
  scale_fill_manual(
    values = c("darkgrey")) +
  scale_color_manual(
    values = c("darkgrey")) +
  theme_void()+
  theme(text = element_text(family = "sans"),
        axis.text = element_text(size = 13),
        axis.title = element_text(size = 13))+
  theme(legend.position= c(0.5, 0.05),
        legend.justification = c(0,1),
        legend.key.size = unit(1, "mm")) +
  theme(legend.direction="horizontal",
        legend.position = "bottom",
        legend.title = element_text(size =10),
        legend.text = element_text(size = 10))
```
http://127.0.0.1:35789/graphics/plot_zoom_png?width=1200&height=900
#SFxOTC
```{r SFxOTC}

#total
OTC_SF_total <- rma.mv(yi, vi, 
                       #mods= ~site_id,
                random=list(~ 1 | site_id, 
                            ~ flux_year | site_id), 
                struct="CAR", 
                data=subset(effect_sizes, treatment_tr=="OTCxSNOWFENCE"))
summary(OTC_SF_total)
forest(OTC_SF_total,
       overall = TRUE)
predict(OTC_SF_total)

#OTC_SF_na <- otc_sf_effect_sizes[complete.cases(otc_sf_effect_sizes$yi_otc_sf), ]

model_results_OTC_SF <- orchaRd::mod_results(OTC_SF_total, mod = "1", group="site_id", data=effect_sizes)

orchard_plot(model_results_OTC_SF, mod = "1", transfm = "none",
             xlab = "Ecosystem Respiration SMD",
             trunk.size = 0.8)+
  scale_fill_manual(
    values = c("darkgrey")) +
  scale_color_manual(
    values = c("darkgrey")) +
  theme_void()+
  theme(text = element_text(family = "sans"),
        axis.text = element_text(size = 13),
        axis.title = element_text(size = 13))+
  theme(legend.position= c(0.5, 0.05),
        legend.justification = c(0,1),
        legend.key.size = unit(1, "mm")) +
  theme(legend.direction="horizontal",
        legend.position = "bottom",
        legend.title = element_text(size =10),
        legend.text = element_text(size = 10))
```
## MAP
```{r map}
#### circumpolar map #####
library(ggplot2)
library(rgdal)                                                                                                      
library(raster)
library(dplyr)

sessionInfo()

# # add country code
# library(countrycode)
# dat$Code<- countrycode(dat$Country, origin = 'country.name', destination = 'iso3c')
# #does not recognize Svalbard -> manually change NA to SJM
# dat$Code[is.na(dat$Code)] <- "SJM"
# 
# # number of years as radius
# years<-dat %>% dplyr::count(site_ID) 
# #rename n in "number of experiments"
# #merge with dat
# dat<-full_join(dat,years)
# n<-as.numeric(dat$n)
# 
# # observations per site as color gradient
# obs<-dat %>% dplyr::group_by(Site_ID)  %>% 
#   summarise(obs_sum = sum(Nr_Obs))
# 
# 
# # observations per site as color gradient
# sumi<-dat %>% dplyr::group_by(Site_ID)  %>% 
#   summarise(obs_sum = sum(Nr_Obs),
#             n = n(),
#             Longitude..DD. = unique(Longitude..DD.),
#             Latitude..DD. = unique(Latitude..DD.),
#             Country = unique(Country))
# #rename n in "number of experiments"
# #merge with dat
# dat<-full_join(dat,obs)
# obs_sum<-as.numeric(dat$obs_sum)
# 
# dat$Nr_Obs

working_data$n_coord_plot_dd<-as.numeric(working_data$n_coord_plot_dd)
working_data$e_coord_plot_dd<-as.numeric(working_data$e_coord_plot_dd)
unique_data <- distinct(working_data, site_id, e_coord_plot_dd, n_coord_plot_dd, treatment)  # Replace 'lon' and 'lat' with your coordinate column names

# get map data
thismap = map_data("world")

# Defines the x axes required
x_lines <- seq(-120,180, by = 60)

# Now modify the ggplot code
Karte<-ggplot() +
  geom_polygon(data = thismap, aes(x = long, y = lat, group = group), fill = "lightgrey", colour = "lightgrey") +
  
  # Convert to polar coordinates
  coord_map("ortho", orientation = c(90, 0, 0)) +
  scale_y_continuous(breaks = seq(30, 90, by = 10), labels = NULL) +
  
  # Adds points for all treatments except "OTCxSNOWFENCE"
  geom_point(data=subset(unique_data, treatment != "CTL" & treatment != "OTCxSNOWFENCE"), aes(x=e_coord_plot_dd, y=n_coord_plot_dd,   
              group=treatment, 
              fill=treatment,
              pch=treatment  # Map the shape to the new shape column
              ),
       color="black",
       alpha=0.6,
       size=3) +  
  
  # Adds points for "OTCxSNOWFENCE" with no transparency
  geom_point(data=subset(unique_data, treatment == "OTCxSNOWFENCE"), aes(x=e_coord_plot_dd, y=n_coord_plot_dd,   
              group=treatment, 
              fill=treatment,
            pch=treatment  # Map the shape to the new shape column
              ),
       color="black",
       alpha=1,  # No transparency
       size=3.2) +  
  
  # geom_point(data=subset(unique_data, treatment != "CTL"), aes(x=e_coord_site, y=n_coord_site,   
  #             group=treatment, 
  #             fill=treatment,
  #             pch=treatment  # Map the pch to the new shape column
  #             ),
  #      color="black",
  #      alpha=0.6,
  #      size=3) +  
  scale_fill_viridis_d(name = "treatment", limits =c("OTC","OTCxSNOWFENCE","SNOWFENCE"), direction=-1) + # add color gradient
  scale_shape_manual(values = c(21, 22, 24), limits =c("OTC","OTCxSNOWFENCE","SNOWFENCE")) +  # Define the shapes manually
  
  # Removes Axes and labels
  scale_x_continuous(breaks = NULL) +
  xlab("") +
  ylab("") +
  
  # Adds labels
  geom_text(aes(x = 180, y = seq(45, 85, by = 20), hjust = -0.2, label = paste0(seq(45, 85, by = 20), "°N"))) +
  geom_text(aes(x = x_lines, y = 15, label = c("120°W", "60°W", "0°", "60°E", "120°E", "180°W"))) +
  
  # Adds axes
  geom_segment(aes(y = 10, yend = 90, x = x_lines, xend = x_lines), linetype = "dashed") +
  
  # Change theme to remove axes and ticks
  theme(panel.background = element_blank(),
    panel.grid.major = element_line(size = 0.25, linetype = 'dashed',
                    colour = "darkgrey"),
    axis.ticks=element_blank(),
    legend.position = "top") 

```

# Where is the site_level data in the working_data file?
```{r PF categories for Mats}

#Mats needs: permafrost layers, site id_site_name; coordinates; vegetation on plot level 
PF_data_plot <- distinct(working_data, site_id, flux_year, plot_id, e_coord_plot_dd, n_coord_plot_dd, treatment, veg_type_site, veg_class_site, pf_site)  
PF_data_site <- distinct(working_data, site_id, year, e_coord_plot_dd, n_coord_plot_dd, treatment, veg_type_site, veg_class_site, pf_site) 

contacts_flux_data <- read_csv("contacts flux data_local copy.csv")

#merge site_name; larger site name and site_id
PF_plot <- dplyr::left_join(PF_data_plot, contacts_flux_data, by = "site_id")
PF_site <- dplyr::left_join(PF_data_site, contacts_flux_data, by = "site_id")

write.csv(PF_site, "PF_site.csv")

```
```{r quick plots}
library(RColorBrewer)
ggplot(subset(working_data, treatment!="CTL"), aes(x = as.factor(treatment), y = co2, fill=treatment)) +
  geom_col() +  # Adjust fill color as desired
  scale_fill_brewer(palette = "BuPu")+
  coord_polar()+  # Transform to circular coordinates
  theme_minimal()

ggplot(effect_df, aes(x = site_id, y = mean_sf, fill=site_id)) +
  geom_col() +  # Adjust fill color as desired
  scale_fill_brewer(palette = "BuPu")+
  coord_polar()+  # Transform to circular coordinates
  theme_minimal()

```


```{r data from Hermesdorf et al paper}

Hermesdorf<- read_csv("~/1_projects and publications/4_flux data/1_winter flux data/4_new data/extract from literature/GCB_Hermesdorf_et_al.csv")
# Function to convert mg CO2/m²/h to g C-CO2/m²/d
convert_respiration <- function(mg_CO2_per_m2_per_h) {
  # Conversion factors
  mg_to_g <- 1 / 1000                # 1000 mg in a gram
  hours_per_day <- 24                # 24 hours in a day
  fraction_C_in_CO2 <- 12 / 44       # Molecular weight ratio of C to CO2
  
  # Conversion calculation
  g_C_CO2_per_m2_per_d <- mg_CO2_per_m2_per_h * mg_to_g * hours_per_day * fraction_C_in_CO2
  
  return(g_C_CO2_per_m2_per_d)
}

# Example usage
mg_CO2_per_m2_per_h <- 245.916  # Replace with your value
g_C_CO2_per_m2_per_d <- convert_respiration(mg_CO2_per_m2_per_h)
cat(mg_CO2_per_m2_per_h, "mg CO2/m²/h is equivalent to", g_C_CO2_per_m2_per_d, "g C-CO2/m²/d\n")

## Tranform the whole coloumn
# Load necessary library

# Function to convert mg CO2/m²/h to g C-CO2/m²/d
convert_respiration <- function(mg_CO2_per_m2_per_h) {
  # Conversion factors
  mg_to_g <- 1 / 1000                # 1000 mg in a gram
  hours_per_day <- 24                # 24 hours in a day
  fraction_C_in_CO2 <- 12 / 44       # Molecular weight ratio of C to CO2
  
  # Conversion calculation
  g_C_CO2_per_m2_per_d <- mg_CO2_per_m2_per_h * mg_to_g * hours_per_day * fraction_C_in_CO2
  
  return(g_C_CO2_per_m2_per_d)
}

# Apply conversion function to the entire column
data <- Hermesdorf %>%
  mutate(g_C_CO2_per_m2_per_d = sapply(ER, convert_respiration))

# Print the updated data frame
write.csv(data, "~/1_projects and publications/4_flux data/1_winter flux data/4_new data/extract from literature/ER_tranformed_Hermesdorf_et_al.csv")

ggplot(subset(all_data_230823, treatment !="CTL"), aes(x = treatment, y = co2)) +
  geom_col(fill = "steelblue") +  # Adjust fill color as desired
  coord_polar()+  # Transform to circular coordinates
  theme_minimal()

plyr::count(all_data_230823$c_loss)
plyr::count(working_data$c_loss)
plyr::count(working_data$treatment)


```


